{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import itertools\n",
    "from itertools import chain\n",
    "import pickle\n",
    "import torch\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import OPTICS\n",
    "from sklearn.metrics.cluster import adjusted_rand_score, adjusted_mutual_info_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import igraph\n",
    "import sys\n",
    "from pytictoc import TicToc\n",
    "import statistics\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "OPTICS\n",
    "Input: ruleBased_DAGs, aggFeatures, vectorDF, multiple types of embeddings\n",
    "Output: Statistical results over performance of different embeddings\n",
    "\n",
    "\n",
    "runtime: ca 2-3 hours (In case of reading already generated OPTICS couple of minitues)\n",
    "Evaluation of different embeddings\n",
    "\n",
    "Notes: \n",
    "\n",
    "(1)The OPTICS models are already stored. The methodology of generating the models are also available. One can uncomment the related part to reproduce the model\n",
    "\n",
    "(2)The embeddings are as follows: \n",
    "AVG:16, 32, 64, 60, 128\n",
    "SUM:32, 60\n",
    "MAX: 32, 60\n",
    "Combination of all: 96 (32+32+32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = TicToc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAG = pd.read_csv(\"data/ruleBased_DAGs.csv\",sep =',')\n",
    "features = pd.read_csv(\"data/aggFeatures.csv\",sep =',')\n",
    "y_vector_df = pd.read_csv(\"data/vectorDF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs['cat_run_time'] = pd.cut(DAGs.run_time, bins = list(range(0,3600,100)), labels=np.arange(35), right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedDf = pd.read_csv(\"data/embedding_model_multisimilarityLoss_11Ys_30Epochs_train_test_stratified.csv\")\n",
    "embedDf180 = pd.read_csv(\"data/model_MultiSimilarityLoss_11Ys_70Epochs_train_test_stratified_3Gpoolinglayers180.csv\")\n",
    "embedDf64 = pd.read_csv(\"data/model_C_TripletMarginLoss2_distanceCosineSimilarity_11Ys_70Epochs_train_test_stratified_globalavg64.csv\")\n",
    "embedDf128 = pd.read_csv(\"data/model_C_TripletMarginLoss2_distanceCosineSimilarity_11Ys_70Epochs_train_test_stratified_globalavg128.csv\")\n",
    "embedDf16 = pd.read_csv(\"data/model_C_TripletMarginLoss2_distanceCosineSimilarity_11Ys_70Epochs_train_test_stratified_globalavg16.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedDf = embedDf.drop(['Unnamed: 0'], axis=1)\n",
    "embedDf.fillna(method ='ffill', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "### breaking the embedding dataframe in three fields: max-avg-add for different embedding size\n",
    "embedDf_max = embedDf.iloc[:,0:32]\n",
    "embedDf_avg = embedDf.iloc[:,32:64]\n",
    "embedDf_add = embedDf.iloc[:,64:96]\n",
    "embedDf_all = embedDf.iloc[:,0:96]\n",
    "embedDf_max_60 = embedDf180.iloc[:,1:60]\n",
    "embedDf_avg_60 = embedDf180.iloc[:,60:120]\n",
    "embedDf_add_60 = embedDf180.iloc[:,120:180]\n",
    "embedDf_all_60 = embedDf180.iloc[:,1:180]\n",
    "embedDf_avg64 = embedDf64.iloc[:,0:64]\n",
    "embedDf_avg128 = embedDf128.iloc[:,1:129]\n",
    "embedDf_avg16 = embedDf16.iloc[:,1:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = embedDf.iloc[:,0:96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standardization and Normalization ###\n",
    "\n",
    "scaler = StandardScaler() \n",
    "\n",
    "\n",
    "#size of 32\n",
    "DF_scaled_max = scaler.fit_transform(embedDf_max)\n",
    "DF_scaled_avg = scaler.fit_transform(embedDf_avg)\n",
    "DF_scaled_add = scaler.fit_transform(embedDf_add)\n",
    "DF_scaled_all = scaler.fit_transform(embedDf_all)\n",
    "\n",
    "\n",
    "#size of 60\n",
    "DF_scaled_max_60 = scaler.fit_transform(embedDf_max_60)\n",
    "DF_scaled_avg_60 = scaler.fit_transform(embedDf_avg_60)\n",
    "DF_scaled_add_60 = scaler.fit_transform(embedDf_add_60)\n",
    "\n",
    "\n",
    "\n",
    "#different sized of AVG\n",
    "DF_scaled_avg16 = scaler.fit_transform(embedDf_avg16)\n",
    "DF_scaled_avg64 = scaler.fit_transform(embedDf_avg64)\n",
    "DF_scaled_avg128 = scaler.fit_transform(embedDf_avg128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "\n",
    "#size of 32\n",
    "DF_normalized_max = normalize(DF_scaled_max)\n",
    "DF_normalized_avg = normalize(DF_scaled_avg) \n",
    "DF_normalized_add = normalize(DF_scaled_add) \n",
    "DF_normalized_all = normalize(DF_scaled_all) \n",
    "\n",
    "#size of 60\n",
    "DF_normalized_max_60 = normalize(DF_scaled_max_60)\n",
    "DF_normalized_avg_60 = normalize(DF_scaled_avg_60) \n",
    "DF_normalized_add_60 = normalize(DF_scaled_add_60) \n",
    "\n",
    "\n",
    "#different sized of AVG\n",
    "DF_normalized_avg16 = normalize(DF_scaled_avg16)\n",
    "DF_normalized_avg64 = normalize(DF_scaled_avg64) \n",
    "DF_normalized_avg128 = normalize(DF_scaled_avg128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time.tic()\n",
    "#optics_model = OPTICS()\n",
    "#optics_avg_64 = optics_model.fit(DF_normalized_avg64)\n",
    "#pickle.dump(optics_avg_64, open('models/optics_avg64_clusterSize_2_only20nodes.sav', 'wb'))\n",
    "#time.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### First Checkpoint ####\n",
    "#The model is fitted with all the eleven samples described above# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alireza.alamgiralem/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator OPTICS from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "optic_max = pickle.load(open('models/optic_max.sav', 'rb'))\n",
    "optic_add = pickle.load(open('models/optic_add.sav', 'rb'))\n",
    "optic_all = pickle.load(open('models/optic_all.sav', 'rb'))\n",
    "optic_avg = pickle.load(open('models/optic_avg.sav', 'rb'))\n",
    "optic_avg16 = pickle.load(open('models/optic_avg16.sav', 'rb'))\n",
    "optic_avg64 = pickle.load(open('models/optic__avg_64.sav', 'rb'))\n",
    "optic_avg128 = pickle.load(open('models/optic__avg_128.sav', 'rb'))\n",
    "optic_max_60 = pickle.load(open('models/optic_max_60.sav', 'rb'))\n",
    "optic_add_60 = pickle.load(open('models/optic_add_60.sav', 'rb'))\n",
    "optic_avg_60 = pickle.load(open('models/optic_avg_60.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#32\n",
    "labels_max = list(optic_max.labels_)\n",
    "labels_avg = list(optic_avg.labels_)\n",
    "labels_add = list(optic_add.labels_)\n",
    "labels_all = list(optic_all.labels_)\n",
    "\n",
    "#60\n",
    "labels_max_60 = list(optic_max_60.labels_)\n",
    "labels_avg_60 = list(optic_avg_60.labels_)\n",
    "labels_add_60 = list(optic_add_60.labels_)\n",
    "\n",
    "\n",
    "#only avg\n",
    "labels_avg16 = list(optic_avg16.labels_)\n",
    "labels_avg64 = list(optic_avg64.labels_)\n",
    "lables_avg128 = list(optic_avg128.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning different labels to a single the dataframe\n",
    "\n",
    "#32\n",
    "embedDf = embedDf.assign(OPTIC_labels_max = labels_max)\n",
    "embedDf = embedDf.assign(OPTIC_labels_avg = labels_avg)\n",
    "embedDf = embedDf.assign(OPTIC_labels_add = labels_add)\n",
    "embedDf = embedDf.assign(OPTIC_labels_all = labels_all)\n",
    "\n",
    "#60\n",
    "embedDf = embedDf.assign(OPTIC_labels_max_60 = labels_max_60)\n",
    "embedDf = embedDf.assign(OPTIC_labels_avg_60 = labels_avg_60)\n",
    "embedDf = embedDf.assign(OPTIC_labels_add_60 = labels_add_60)\n",
    "\n",
    "#avg\n",
    "embedDf = embedDf.assign(OPTIC_labels_avg16 = labels_avg16)\n",
    "embedDf = embedDf.assign(OPTIC_labels_avg64 = labels_avg64)\n",
    "embedDf = embedDf.assign(OPTIC_labels_avg128 = lables_avg128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs = pd.merge(DAG, features, how='inner', on = 'job_name')\n",
    "DAGs = DAGs.drop('Unnamed: 0', axis=1)\n",
    "joinTable = pd.merge(DAGs, embedDf, on = 'job_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation of group sizes for different clusters\n",
    "joinTable['lableSize_group'] = joinTable.groupby('group')['group'].transform('size')\n",
    "\n",
    "joinTable['lableSize_max'] = joinTable.groupby('OPTIC_labels_max')['OPTIC_labels_max'].transform('size')\n",
    "joinTable['lableSize_avg'] = joinTable.groupby('OPTIC_labels_avg')['OPTIC_labels_avg'].transform('size')\n",
    "joinTable['lableSize_add'] = joinTable.groupby('OPTIC_labels_add')['OPTIC_labels_add'].transform('size')\n",
    "joinTable['lableSize_all'] = joinTable.groupby('OPTIC_labels_all')['OPTIC_labels_all'].transform('size')\n",
    "\n",
    "\n",
    "joinTable['lableSize_max_60'] = joinTable.groupby('OPTIC_labels_max_60')['OPTIC_labels_max_60'].transform('size')\n",
    "joinTable['lableSize_avg_60'] = joinTable.groupby('OPTIC_labels_avg_60')['OPTIC_labels_avg_60'].transform('size')\n",
    "joinTable['lableSize_add_60'] = joinTable.groupby('OPTIC_labels_add_60')['OPTIC_labels_add_60'].transform('size')\n",
    "\n",
    "\n",
    "joinTable['lableSize_avg16'] = joinTable.groupby('OPTIC_labels_avg16')['OPTIC_labels_avg16'].transform('size')\n",
    "joinTable['lableSize_avg64'] = joinTable.groupby('OPTIC_labels_avg64')['OPTIC_labels_avg64'].transform('size')\n",
    "joinTable['lableSize_avg128'] = joinTable.groupby('OPTIC_labels_avg128')['OPTIC_labels_avg128'].transform('size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_group = list(joinTable.group.unique())\n",
    "\n",
    "#32\n",
    "set_lables_max = list(joinTable.OPTIC_labels_max.unique())\n",
    "set_lables_avg = list(joinTable.OPTIC_labels_avg.unique())\n",
    "set_lables_add = list(joinTable.OPTIC_labels_add.unique())\n",
    "set_lables_all = list(joinTable.OPTIC_labels_all.unique())\n",
    "\n",
    "#60\n",
    "set_lables_max_60 = list(joinTable.OPTIC_labels_max_60.unique())\n",
    "set_lables_avg_60 = list(joinTable.OPTIC_labels_avg_60.unique())\n",
    "set_lables_add_60 = list(joinTable.OPTIC_labels_add_60.unique())\n",
    "\n",
    "set_lables_avg16 = list(joinTable.OPTIC_labels_avg16.unique())\n",
    "set_lables_avg64 = list(joinTable.OPTIC_labels_avg64.unique())\n",
    "set_lables_avg128 = list(joinTable.OPTIC_labels_avg128.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var by max =  49953.59310954847\n",
      "var by avg =  46965.61294763679\n",
      "var by add =  47012.049164246746\n",
      "var by all =  46691.360406226566\n",
      "\n",
      "\n",
      " embedding size of 60\n",
      "var by max_60 =  43020.78508412694\n",
      "var by avg_60 =  37046.70788939994\n",
      "var by add_60 =  36408.29908553091\n",
      "\n",
      "\n",
      "labels generated by other settings\n",
      "var by avg 16 =  30622.31521614127\n",
      "var by avg 64 =  30465.134276891633\n",
      "var by avg 128 =  39938.6161891401\n"
     ]
    }
   ],
   "source": [
    "## Calculation of variance with outliers\n",
    "\n",
    "#calculating the variance for every group (by OPTIC_max)\n",
    "var_by_optic_max = list()\n",
    "for i in set_lables_max:\n",
    "    df = joinTable[joinTable.OPTIC_labels_max == i]\n",
    "    var_by_optic_max.append(np.var(df.run_time))   \n",
    "print('var by max = ',np.mean(var_by_optic_max))\n",
    "\n",
    "#calculating the variance for every group (by OPTIC_avg)\n",
    "var_by_optic_avg = list()\n",
    "for i in set_lables_avg:\n",
    "    df = joinTable[joinTable.OPTIC_labels_avg == i]\n",
    "    var_by_optic_avg.append(np.var(df.run_time))   \n",
    "print('var by avg = ',np.mean(var_by_optic_avg))\n",
    "\n",
    "#calculating the variance for every group (by OPTIC_add)\n",
    "var_by_optic_add = list()\n",
    "for i in set_lables_add:\n",
    "    df = joinTable[joinTable.OPTIC_labels_add == i]\n",
    "    var_by_optic_add.append(np.var(df.run_time))   \n",
    "print('var by add = ',np.mean(var_by_optic_add))\n",
    "\n",
    "#calculating the variance for every group (by OPTIC_add)\n",
    "var_by_optic_all = list()\n",
    "for i in set_lables_all:\n",
    "    df = joinTable[joinTable.OPTIC_labels_all == i]\n",
    "    var_by_optic_all.append(np.var(df.run_time))   \n",
    "print('var by all = ',np.mean(var_by_optic_all))\n",
    "\n",
    "print('\\n\\n embedding size of 60')\n",
    "#########60\n",
    "#calculating the variance for every group (by OPTIC_max)\n",
    "var_by_optic_max_60 = list()\n",
    "for i in set_lables_max_60:\n",
    "    df = joinTable[joinTable.OPTIC_labels_max_60 == i]\n",
    "    var_by_optic_max_60.append(np.var(df.run_time))   \n",
    "print('var by max_60 = ',np.mean(var_by_optic_max_60))\n",
    "\n",
    "#calculating the variance for every group (by OPTIC_avg)\n",
    "var_by_optic_avg_60 = list()\n",
    "for i in set_lables_avg_60:\n",
    "    df = joinTable[joinTable.OPTIC_labels_avg_60 == i]\n",
    "    var_by_optic_avg_60.append(np.var(df.run_time))   \n",
    "print('var by avg_60 = ',np.mean(var_by_optic_avg_60))\n",
    "\n",
    "#calculating the variance for every group (by OPTIC_add)\n",
    "var_by_optic_add_60 = list()\n",
    "for i in set_lables_add_60:\n",
    "    df = joinTable[joinTable.OPTIC_labels_add_60 == i]\n",
    "    var_by_optic_add_60.append(np.var(df.run_time))   \n",
    "print('var by add_60 = ',np.mean(var_by_optic_add_60))\n",
    "\n",
    "\n",
    "print('\\n\\nlabels generated by other settings')\n",
    "\n",
    "\n",
    "\n",
    "#calculating the variance for every group (by OPTIC_avg16)\n",
    "var_by_optic_avg16 = list()\n",
    "for i in set_lables_avg16:\n",
    "    df = joinTable[joinTable.OPTIC_labels_avg16 == i]\n",
    "    var_by_optic_avg16.append(np.var(df.run_time))   \n",
    "print('var by avg 16 = ',np.mean(var_by_optic_avg16))\n",
    "\n",
    "#calculating the variance for every group (by OPTIC_avg64)\n",
    "var_by_optic_avg64 = list()\n",
    "for i in set_lables_avg64:\n",
    "    df = joinTable[joinTable.OPTIC_labels_avg64 == i]\n",
    "    var_by_optic_avg64.append(np.var(df.run_time))   \n",
    "print('var by avg 64 = ',np.mean(var_by_optic_avg64))\n",
    "\n",
    "#calculating the variance for every group (by OPTIC_avg128)\n",
    "var_by_optic_avg128 = list()\n",
    "for i in set_lables_avg128:\n",
    "    df = joinTable[joinTable.OPTIC_labels_avg128 == i]\n",
    "    var_by_optic_avg128.append(np.var(df.run_time))   \n",
    "print('var by avg 128 = ',np.mean(var_by_optic_avg128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlierdeletor (cluster_list):\n",
    "    if -1 in cluster_list:\n",
    "        cluster_list.remove(-1)\n",
    "    return cluster_list\n",
    "#32\n",
    "set_lables_max = outlierdeletor(set_lables_max)\n",
    "set_lables_avg = outlierdeletor(set_lables_avg)\n",
    "set_lables_add = outlierdeletor(set_lables_add)\n",
    "set_lables_all = outlierdeletor(set_lables_all)\n",
    "\n",
    "#60\n",
    "set_lables_max_60 = outlierdeletor(set_lables_max_60)\n",
    "set_lables_avg_60 = outlierdeletor(set_lables_avg_60)\n",
    "set_lables_add_60 = outlierdeletor(set_lables_add_60)\n",
    "\n",
    "#avg\n",
    "set_lables_avg16 = outlierdeletor(set_lables_avg16)\n",
    "set_lables_avg64 = outlierdeletor(set_lables_avg64)\n",
    "set_lables_avg128 = outlierdeletor(set_lables_avg128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var by previous groups =  40823.22516285953\n",
      "beseline (group size bigger than 5)\n",
      "var by previous groups =  50127.79864920701\n",
      "\n",
      "\n",
      "embeddings size of 32\n",
      "var by max =  49953.59310954847\n",
      "var by avg =  46965.61294763679\n",
      "var by add =  47012.049164246746\n",
      "var by all =  46691.360406226566\n",
      "\n",
      "\n",
      " embedding size of 60\n",
      "var by max_60 =  43020.78508412694\n",
      "var by avg_60 =  37046.70788939994\n",
      "var by add_60 =  36408.29908553091\n",
      "\n",
      "\n",
      " different sizes of average\n",
      "var by avg 16 =  30622.31521614127\n",
      "var by avg 64 =  30465.134276891633\n",
      "var by avg 128 =  39938.6161891401\n"
     ]
    }
   ],
   "source": [
    "# Rule-based\n",
    "var_by_group_inlier = list()\n",
    "for i in set_group:\n",
    "    df = joinTable[(joinTable.group == i) & (joinTable.lableSize_group >= 2) ]\n",
    "    var_by_group_inlier.append(np.var(df.run_time))\n",
    "print('var by previous groups = ',np.nanmean(var_by_group_inlier))\n",
    "\n",
    "print('beseline (group size bigger than 5)')\n",
    "var_by_group_inlier_5 = list()\n",
    "for i in set_group:\n",
    "    df = joinTable[(joinTable.group == i) & (joinTable.lableSize_group >= 5) ]\n",
    "    var_by_group_inlier_5.append(np.var(df.run_time))\n",
    "print('var by previous groups = ',np.nanmean(var_by_group_inlier_5))\n",
    "\n",
    "print('\\n\\nembeddings size of 32')\n",
    "\n",
    "#######32######\n",
    "#calculating the variance for every group (by OPTIC_max)\n",
    "var_by_optic_max_inlier = list()\n",
    "for i in set_lables_max:\n",
    "    df = joinTable[joinTable.OPTIC_labels_max == i]\n",
    "    var_by_optic_max_inlier.append(np.var(df.run_time))   \n",
    "print('var by max = ',np.mean(var_by_optic_max_inlier))\n",
    "\n",
    "#calculating the variance for every group (by OPTIC_avg)\n",
    "var_by_optic_avg_inlier = list()\n",
    "for i in set_lables_avg:\n",
    "    df = joinTable[joinTable.OPTIC_labels_avg == i]\n",
    "    var_by_optic_avg_inlier.append(np.var(df.run_time))   \n",
    "print('var by avg = ',np.mean(var_by_optic_avg_inlier))\n",
    "\n",
    "#calculating the variance for every group (by OPTIC_add)\n",
    "var_by_optic_add_inlier = list()\n",
    "for i in set_lables_add:\n",
    "    df = joinTable[joinTable.OPTIC_labels_add == i]\n",
    "    var_by_optic_add_inlier.append(np.var(df.run_time))   \n",
    "print('var by add = ',np.mean(var_by_optic_add_inlier))\n",
    "\n",
    "#calculating the variance for every group (by OPTIC_add)\n",
    "var_by_optic_all_inlier = list()\n",
    "for i in set_lables_all:\n",
    "    df = joinTable[joinTable.OPTIC_labels_all == i]\n",
    "    var_by_optic_all_inlier.append(np.var(df.run_time))   \n",
    "print('var by all = ',np.mean(var_by_optic_all_inlier))\n",
    "\n",
    "print('\\n\\n embedding size of 60')\n",
    "#########60\n",
    "#calculating the variance for every group (by OPTIC_max)\n",
    "var_by_optic_max_60_inlier = list()\n",
    "for i in set_lables_max_60:\n",
    "    df = joinTable[joinTable.OPTIC_labels_max_60 == i]\n",
    "    var_by_optic_max_60_inlier.append(np.var(df.run_time))   \n",
    "print('var by max_60 = ',np.mean(var_by_optic_max_60_inlier))\n",
    "\n",
    "#calculating the variance for every group (by OPTIC_avg)\n",
    "var_by_optic_avg_60_inlier = list()\n",
    "for i in set_lables_avg_60:\n",
    "    df = joinTable[joinTable.OPTIC_labels_avg_60 == i]\n",
    "    var_by_optic_avg_60_inlier.append(np.var(df.run_time))   \n",
    "print('var by avg_60 = ',np.mean(var_by_optic_avg_60_inlier))\n",
    "\n",
    "#calculating the variance for every group (by OPTIC_add)\n",
    "var_by_optic_add_60_inlier = list()\n",
    "for i in set_lables_add_60:\n",
    "    df = joinTable[joinTable.OPTIC_labels_add_60 == i]\n",
    "    var_by_optic_add_60_inlier.append(np.var(df.run_time))   \n",
    "print('var by add_60 = ',np.mean(var_by_optic_add_60_inlier))\n",
    "\n",
    "\n",
    "print('\\n\\n different sizes of average')\n",
    "#calculating the variance for every group (by OPTIC_avg16)\n",
    "var_by_optic_avg16_inlier = list()\n",
    "for i in set_lables_avg16:\n",
    "    df = joinTable[joinTable.OPTIC_labels_avg16 == i]\n",
    "    var_by_optic_avg16_inlier.append(np.var(df.run_time))   \n",
    "print('var by avg 16 = ',np.mean(var_by_optic_avg16_inlier))\n",
    "\n",
    "#calculating the variance for every group (by OPTIC_avg64)\n",
    "var_by_optic_avg64_inlier = list()\n",
    "for i in set_lables_avg64:\n",
    "    df = joinTable[joinTable.OPTIC_labels_avg64 == i]\n",
    "    var_by_optic_avg64_inlier.append(np.var(df.run_time))   \n",
    "print('var by avg 64 = ',np.mean(var_by_optic_avg64_inlier))\n",
    "\n",
    "#calculating the variance for every group (by OPTIC_avg128)\n",
    "var_by_optic_avg128_inlier = list()\n",
    "for i in set_lables_avg128:\n",
    "    df = joinTable[joinTable.OPTIC_labels_avg128 == i]\n",
    "    var_by_optic_avg128_inlier.append(np.var(df.run_time))   \n",
    "print('var by avg 128 = ',np.mean(var_by_optic_avg128_inlier))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description of baseline groups smallest group size of 2 \n",
      "number of groups = 24961\n",
      "biggest group size =  1904 \n",
      "avg size of groups =  9\n",
      "number of outliers =  17117\n",
      "runtime variation of outliers =  283197.05708497413\n",
      "runtime variation of inliers =  40823.22516285953 \n",
      "\n",
      "\n",
      "description of baseline groups smallest group size of 5 \n",
      "number of groups = 24961\n",
      "biggest group size =  1904 \n",
      "avg size of groups =  17\n",
      "number of outliers =  56759\n",
      "runtime variation of outliers =  264161.92108860996\n",
      "runtime variation of inliers =  50127.79864920701 \n",
      "\n",
      "\n",
      "description of labeles with embedding size of 32 (MAX)\n",
      "number of groups =  13619\n",
      "biggest group size =  2488 \n",
      "avg size of groups =  16\n",
      "number of outliers =  9279\n",
      "mean runtime variation of outliers =  49953.59310954847\n",
      "mean runtime variation of inliers =  49953.59310954847 \n",
      "\n",
      "\n",
      "description of labeles with embedding size of 32 (AVG)\n",
      "number of groups =  13619\n",
      "biggest group size =  2016 \n",
      "avg size of groups =  15\n",
      "number of outliers =  10320\n",
      "mean runtime variation of outliers =  46965.61294763679\n",
      "mean runtime variation of inliers =  46965.61294763679 \n",
      "\n",
      "\n",
      "description of labeles with embedding size of 32 (ADD)\n",
      "number of groups =  13619\n",
      "biggest group size =  2016 \n",
      "avg size of groups =  15\n",
      "number of outliers =  10326\n",
      "mean runtime variation of outliers =  47012.049164246746\n",
      "mean runtime variation of inliers =  47012.049164246746 \n",
      "\n",
      "\n",
      "description of labeles with embedding size of 32 (all) (96)\n",
      "number of groups =  14510\n",
      "biggest group size =  2016 \n",
      "avg size of groups =  15\n",
      "number of outliers =  10040\n",
      "mean runtime variation of outliers =  46691.360406226566\n",
      "mean runtime variation of inliers =  46691.360406226566 \n",
      "\n",
      "\n",
      "description of labeles with embedding size of 60 (MAX) \n",
      "number of groups =  16583\n",
      "biggest group size =  6009 \n",
      "avg size of groups =  13\n",
      "number of outliers =  25209\n",
      "mean runtime variation of outliers =  43020.78508412694\n",
      "mean runtime variation of inliers =  43020.78508412694 \n",
      "\n",
      "\n",
      "description of labeles with embedding size of 60 (AVG) \n",
      "number of groups =  19672\n",
      "biggest group size =  121 \n",
      "avg size of groups =  8\n",
      "number of outliers =  66927\n",
      "mean runtime variation of outliers =  37046.70788939994\n",
      "mean runtime variation of inliers =  37046.70788939994 \n",
      "\n",
      "\n",
      "description of labeles with embedding size of 60 (ADD) \n",
      "number of groups =  19693\n",
      "biggest group size =  233 \n",
      "avg size of groups =  8\n",
      "number of outliers =  66599\n",
      "mean runtime variation of outliers =  36408.29908553091\n",
      "mean runtime variation of inliers =  36408.29908553091 \n",
      "\n",
      "\n",
      "description of labeles with embedding size of 16 (AVG) \n",
      "number of groups =  22130\n",
      "biggest group size =  168 \n",
      "avg size of groups =  8\n",
      "number of outliers =  50798\n",
      "mean runtime variation of outliers =  30622.31521614127\n",
      "mean runtime variation of inliers =  30622.31521614127 \n",
      "\n",
      "\n",
      "description of labeles with embedding size of 64 (AVG) \n",
      "number of groups =  22384\n",
      "biggest group size =  168 \n",
      "avg size of groups =  8\n",
      "number of outliers =  60205\n",
      "mean runtime variation of outliers =  30465.134276891633\n",
      "mean runtime variation of inliers =  30465.134276891633 \n",
      "\n",
      "\n",
      "description of labeles with embedding size of 128 (AVG) \n",
      "number of groups =  17379\n",
      "biggest group size =  1711 \n",
      "avg size of groups =  10\n",
      "number of outliers =  66263\n",
      "mean runtime variation of outliers =  39938.6161891401\n",
      "mean runtime variation of inliers =  39938.6161891401 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#exploring lables\n",
    "\n",
    "print ('description of baseline groups smallest group size of 2 \\nnumber of groups =', len(set_group))\n",
    "df = joinTable[joinTable.lableSize_group >= 2]\n",
    "df = df.drop_duplicates(subset=['group'])\n",
    "print('biggest group size = ',max(df.lableSize_group), '\\navg size of groups = ', round(np.mean(df.lableSize_group)))\n",
    "print('number of outliers = ' ,len(joinTable[joinTable.lableSize_group < 2]))\n",
    "print('runtime variation of outliers = ', np.var(joinTable[joinTable.lableSize_group < 2].run_time)) \n",
    "print('runtime variation of inliers = ', np.nanmean(var_by_group_inlier),'\\n\\n') \n",
    "\n",
    "print ('description of baseline groups smallest group size of 5 \\nnumber of groups =', len(set_group))\n",
    "df = joinTable[joinTable.lableSize_group >= 5]\n",
    "df = df.drop_duplicates(subset=['group'])\n",
    "print('biggest group size = ',max(df.lableSize_group),'\\navg size of groups = ', round(np.mean(df.lableSize_group)))\n",
    "print('number of outliers = ' ,len(joinTable[joinTable.lableSize_group < 5]))\n",
    "print('runtime variation of outliers = ', np.var(joinTable[joinTable.lableSize_group < 5].run_time)) \n",
    "print('runtime variation of inliers = ', np.nanmean(var_by_group_inlier_5),'\\n\\n')\n",
    "\n",
    "print('description of labeles with embedding size of 32 (MAX)\\nnumber of groups = ', len(set_lables_max))\n",
    "df = joinTable[joinTable.OPTIC_labels_max != -1]\n",
    "df = df.drop_duplicates(subset=['OPTIC_labels_max'])\n",
    "print('biggest group size = ',max(df.lableSize_max), '\\navg size of groups = ', round(np.mean(df.lableSize_max)))\n",
    "print('number of outliers = ' ,len(joinTable[joinTable.OPTIC_labels_max == -1]))\n",
    "print('mean runtime variation of outliers = ', np.mean(var_by_optic_max)) \n",
    "print('mean runtime variation of inliers = ', np.mean(var_by_optic_max_inlier),'\\n\\n') \n",
    "\n",
    "print('description of labeles with embedding size of 32 (AVG)\\nnumber of groups = ', len(set_lables_max))\n",
    "df = joinTable[joinTable.OPTIC_labels_avg != -1]\n",
    "df = df.drop_duplicates(subset=['OPTIC_labels_avg'])\n",
    "print('biggest group size = ',max(df.lableSize_avg), '\\navg size of groups = ', round(np.mean(df.lableSize_avg)))\n",
    "print('number of outliers = ' ,len(joinTable[joinTable.OPTIC_labels_avg == -1]))\n",
    "print('mean runtime variation of outliers = ', np.mean(var_by_optic_avg)) \n",
    "print('mean runtime variation of inliers = ', np.mean(var_by_optic_avg_inlier),'\\n\\n') \n",
    "\n",
    "print('description of labeles with embedding size of 32 (ADD)\\nnumber of groups = ', len(set_lables_max))\n",
    "df = joinTable[joinTable.OPTIC_labels_add != -1]\n",
    "df = df.drop_duplicates(subset=['OPTIC_labels_add'])\n",
    "print('biggest group size = ',max(df.lableSize_add), '\\navg size of groups = ', round(np.mean(df.lableSize_add)))\n",
    "print('number of outliers = ' ,len(joinTable[joinTable.OPTIC_labels_add == -1]))\n",
    "print('mean runtime variation of outliers = ', np.mean(var_by_optic_add)) \n",
    "print('mean runtime variation of inliers = ', np.mean(var_by_optic_add_inlier),'\\n\\n')\n",
    "\n",
    "print('description of labeles with embedding size of 32 (all) (96)\\nnumber of groups = ', len(set_lables_all))\n",
    "df = joinTable[joinTable.OPTIC_labels_all != -1]\n",
    "df = df.drop_duplicates(subset=['OPTIC_labels_all'])\n",
    "print('biggest group size = ',max(df.lableSize_all), '\\navg size of groups = ', round(np.mean(df.lableSize_all)))\n",
    "print('number of outliers = ' ,len(joinTable[joinTable.OPTIC_labels_all == -1]))\n",
    "print('mean runtime variation of outliers = ', np.mean(var_by_optic_all)) \n",
    "print('mean runtime variation of inliers = ', np.mean(var_by_optic_all_inlier),'\\n\\n')\n",
    "\n",
    "print('description of labeles with embedding size of 60 (MAX) \\nnumber of groups = ', len(set_lables_max_60))\n",
    "df = joinTable[joinTable.OPTIC_labels_max_60 != -1]\n",
    "df = df.drop_duplicates(subset=['OPTIC_labels_max_60'])\n",
    "print('biggest group size = ',max(df.lableSize_max_60), '\\navg size of groups = ', round(np.mean(df.lableSize_max_60)))\n",
    "print('number of outliers = ' ,len(joinTable[joinTable.OPTIC_labels_max_60 == -1]))\n",
    "print('mean runtime variation of outliers = ', np.mean(var_by_optic_max_60)) \n",
    "print('mean runtime variation of inliers = ', np.mean(var_by_optic_max_60_inlier),'\\n\\n')\n",
    "\n",
    "print('description of labeles with embedding size of 60 (AVG) \\nnumber of groups = ', len(set_lables_avg_60))\n",
    "df = joinTable[joinTable.OPTIC_labels_avg_60 != -1]\n",
    "df = df.drop_duplicates(subset=['OPTIC_labels_avg_60'])\n",
    "print('biggest group size = ',max(df.lableSize_avg_60), '\\navg size of groups = ', round(np.mean(df.lableSize_avg_60)))\n",
    "print('number of outliers = ' ,len(joinTable[joinTable.OPTIC_labels_avg_60 == -1]))\n",
    "print('mean runtime variation of outliers = ', np.mean(var_by_optic_avg_60)) \n",
    "print('mean runtime variation of inliers = ', np.mean(var_by_optic_avg_60_inlier),'\\n\\n')\n",
    "\n",
    "print('description of labeles with embedding size of 60 (ADD) \\nnumber of groups = ', len(set_lables_add_60))\n",
    "df = joinTable[joinTable.OPTIC_labels_add_60 != -1]\n",
    "df = df.drop_duplicates(subset=['OPTIC_labels_add_60'])\n",
    "print('biggest group size = ',max(df.lableSize_add_60), '\\navg size of groups = ', round(np.mean(df.lableSize_add_60)))\n",
    "print('number of outliers = ' ,len(joinTable[joinTable.OPTIC_labels_add_60 == -1]))\n",
    "print('mean runtime variation of outliers = ', np.mean(var_by_optic_add_60)) \n",
    "print('mean runtime variation of inliers = ', np.mean(var_by_optic_add_60_inlier),'\\n\\n')\n",
    "\n",
    "print('description of labeles with embedding size of 16 (AVG) \\nnumber of groups = ', len(set_lables_avg16))\n",
    "df = joinTable[joinTable.OPTIC_labels_avg16 != -1]\n",
    "df = df.drop_duplicates(subset=['OPTIC_labels_avg16'])\n",
    "print('biggest group size = ',max(df.lableSize_avg16), '\\navg size of groups = ', round(np.mean(df.lableSize_avg16)))\n",
    "print('number of outliers = ' ,len(joinTable[joinTable.OPTIC_labels_avg16 == -1]))\n",
    "print('mean runtime variation of outliers = ', np.mean(var_by_optic_avg16)) \n",
    "print('mean runtime variation of inliers = ', np.mean(var_by_optic_avg16_inlier),'\\n\\n')\n",
    "\n",
    "print('description of labeles with embedding size of 64 (AVG) \\nnumber of groups = ', len(set_lables_avg64))\n",
    "df = joinTable[joinTable.OPTIC_labels_avg64 != -1]\n",
    "df = df.drop_duplicates(subset=['OPTIC_labels_avg64'])\n",
    "print('biggest group size = ',max(df.lableSize_avg64), '\\navg size of groups = ', round(np.mean(df.lableSize_avg64)))\n",
    "print('number of outliers = ' ,len(joinTable[joinTable.OPTIC_labels_avg64 == -1]))\n",
    "print('mean runtime variation of outliers = ', np.mean(var_by_optic_avg64)) \n",
    "print('mean runtime variation of inliers = ', np.mean(var_by_optic_avg64_inlier),'\\n\\n')\n",
    "\n",
    "print('description of labeles with embedding size of 128 (AVG) \\nnumber of groups = ', len(set_lables_avg128))\n",
    "df = joinTable[joinTable.OPTIC_labels_avg128 != -1]\n",
    "df = df.drop_duplicates(subset=['OPTIC_labels_avg128'])\n",
    "print('biggest group size = ',max(df.lableSize_avg128), '\\navg size of groups = ', round(np.mean(df.lableSize_avg128)))\n",
    "print('number of outliers = ' ,len(joinTable[joinTable.OPTIC_labels_avg128 == -1]))\n",
    "print('mean runtime variation of outliers = ', np.mean(var_by_optic_avg128)) \n",
    "print('mean runtime variation of inliers = ', np.mean(var_by_optic_avg128_inlier),'\\n\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
